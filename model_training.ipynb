{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca781193",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m   {\n\u001b[32m      4\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m      6\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Model Training for Product Recommendation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m    ]\n\u001b[32m      9\u001b[39m   },\n\u001b[32m     10\u001b[39m   {\n\u001b[32m     11\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     13\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 1. NLP Model for Text Embeddings [cite: 29]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReasoning: We will use a pre-trained model from the HuggingFace Transformers library to generate sentence embeddings from product titles and descriptions. These embeddings capture the semantic meaning of the text and are ideal for similarity search in a vector database. [cite: 54]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m    ]\n\u001b[32m     17\u001b[39m   },\n\u001b[32m     18\u001b[39m   {\n\u001b[32m     19\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     21\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     22\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     23\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom sentence_transformers import SentenceTransformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Reasoning: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is a lightweight and effective model for generating sentence embeddings. [cite: 54]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel = SentenceTransformer(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproduct_descriptions = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mA stylish and comfortable chair made from sustainable oak.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mA sleek and modern coffee table with a durable steel frame.\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Reasoning: The encode method converts our text descriptions into numerical vectors (embeddings). [cite: 54]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33membeddings = model.encode(product_descriptions)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mShape of embeddings:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, embeddings.shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThese embeddings would be stored in a vector database like Pinecone.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m    ]\n\u001b[32m     39\u001b[39m   },\n\u001b[32m     40\u001b[39m   {\n\u001b[32m     41\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     43\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 2. CV Model for Image Classification/Embeddings [cite: 30]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReasoning: A pre-trained Computer Vision model like ResNet50 will be used to classify product images or generate image embeddings. This allows for visual search capabilities. [cite: 44, 54]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m    ]\n\u001b[32m     47\u001b[39m   },\n\u001b[32m     48\u001b[39m   {\n\u001b[32m     49\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     51\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     52\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     53\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport tensorflow as tf\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Reasoning: Load a pre-trained ResNet50 model without the final classification layer to use it as a feature extractor. [cite: 54]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# base_model = tf.keras.applications.ResNet50(weights=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, include_top=False, pooling=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mavg\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# print(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCV model loaded successfully.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# In a full implementation, we would preprocess images and use base_model.predict() to get embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m    ]\n\u001b[32m     61\u001b[39m   },\n\u001b[32m     62\u001b[39m   {\n\u001b[32m     63\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     65\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     66\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## 3. Model Performance Evaluation (Placeholder) [cite: 55]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReasoning: For the NLP model, evaluation can be done by checking if the cosine similarity between semantically similar product descriptions is high. For the CV model, accuracy on a held-out test set would be the key metric. [cite: 54]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m    ]\n\u001b[32m     69\u001b[39m   },\n\u001b[32m     70\u001b[39m   {\n\u001b[32m     71\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     73\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {},\n\u001b[32m     74\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     75\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     76\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.metrics.pairwise import cosine_similarity\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Reasoning: Calculate the similarity between the two product description embeddings generated earlier. [cite: 54]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     79\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msimilarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     80\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCosine similarity between the two mock products: \u001b[39m\u001b[38;5;132;01m{similarity_score[0][0]:.4f}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# A low score indicates the descriptions are distinct, which is expected for a chair vs. a table.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m    ]\n\u001b[32m     83\u001b[39m   }\n\u001b[32m     84\u001b[39m  ],\n\u001b[32m     85\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     86\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     87\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m   },\n\u001b[32m     91\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     92\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m   }\n\u001b[32m     94\u001b[39m  },\n\u001b[32m     95\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m     96\u001b[39m  \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m\n\u001b[32m     97\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Model Training for Product Recommendation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. NLP Model for Text Embeddings [cite: 29]\\n\",\n",
    "    \"Reasoning: We will use a pre-trained model from the HuggingFace Transformers library to generate sentence embeddings from product titles and descriptions. These embeddings capture the semantic meaning of the text and are ideal for similarity search in a vector database. [cite: 54]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sentence_transformers import SentenceTransformer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Reasoning: 'all-MiniLM-L6-v2' is a lightweight and effective model for generating sentence embeddings. [cite: 54]\\n\",\n",
    "    \"model = SentenceTransformer('all-MiniLM-L6-v2')\\n\",\n",
    "    \"\\n\",\n",
    "    \"product_descriptions = [\\n\",\n",
    "    \"    'A stylish and comfortable chair made from sustainable oak.',\\n\",\n",
    "    \"    'A sleek and modern coffee table with a durable steel frame.'\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Reasoning: The encode method converts our text descriptions into numerical vectors (embeddings). [cite: 54]\\n\",\n",
    "    \"embeddings = model.encode(product_descriptions)\\n\",\n",
    "    \"print('Shape of embeddings:', embeddings.shape)\\n\",\n",
    "    \"print('These embeddings would be stored in a vector database like Pinecone.')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. CV Model for Image Classification/Embeddings [cite: 30]\\n\",\n",
    "    \"Reasoning: A pre-trained Computer Vision model like ResNet50 will be used to classify product images or generate image embeddings. This allows for visual search capabilities. [cite: 44, 54]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Reasoning: Load a pre-trained ResNet50 model without the final classification layer to use it as a feature extractor. [cite: 54]\\n\",\n",
    "    \"# base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\\n\",\n",
    "    \"# print('CV model loaded successfully.')\\n\",\n",
    "    \"# In a full implementation, we would preprocess images and use base_model.predict() to get embeddings.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Model Performance Evaluation (Placeholder) [cite: 55]\\n\",\n",
    "    \"Reasoning: For the NLP model, evaluation can be done by checking if the cosine similarity between semantically similar product descriptions is high. For the CV model, accuracy on a held-out test set would be the key metric. [cite: 54]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics.pairwise import cosine_similarity\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Reasoning: Calculate the similarity between the two product description embeddings generated earlier. [cite: 54]\\n\",\n",
    "    \"similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])\\n\",\n",
    "    \"print(f'Cosine similarity between the two mock products: {similarity_score[0][0]:.4f}')\\n\",\n",
    "    \"# A low score indicates the descriptions are distinct, which is expected for a chair vs. a table.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
